An effective method of contour extraction for SEM image based on DCNN

- Machine learning based method for contour extraction of SEM images
- Custom built DCNN
- Emphasis on CD measurements
- Existing Canny Algorithm for contour extraction mentioned. It fails on poor condition images
- Problem: low contrast SEM images are hard to extract from, existing methods only utilize local info when global 
            info could be leveraged, no distiguishing between top and bottom resist contours, unquality datasets
The deep convolutional neural network:
    - Acts as non-linear mapping from SEM image to contour
    See page 2 

Experiment:
    - Used image denoising and contour refinement
    - 6:2:2 (training:verification:testing) ratio

Results:
    - Evaluated by Fab-centric criteria:
        i  do  not  miss  contour  in  a  visually distinct boundary
        ii do not produce fake contour in background  or  foreground
        iii  flexibility  and  capability  of  repairing broken contours if the broken segments gap is small; 
        iv the contour extraction algorithm should be fast enough to support Fab production needs
    - The DCNN subpressed redundant edges and repaired broken contours within a local area
    - large receptive field and low demand on computation

Citation:
T. Zhou et al., "An effective method of contour extraction for SEM image based on DCNN," 2020 International Workshop on Advanced Patterning Solutions (IWAPS), Chengdu, China, 2020, pp. 1-4, doi: 10.1109/IWAPS51164.2020.9286798. keywords: {Training;Computational modeling;Lithography;Resists;Machine learning;Feature extraction;Real-time systems;SEM images;contour extraction;machine leaning (ML);deep convolution neural network (DCNN)},

@INPROCEEDINGS{9286798,
  author={Zhou, Tao and Shi, Xuelong and YanYan and Li, Chen and Chen, Shoumian and Zhao, Yuhang and Zhou, Wenzhan and Zhou, Kan and Zeng, Xuan},
  booktitle={2020 International Workshop on Advanced Patterning Solutions (IWAPS)}, 
  title={An effective method of contour extraction for SEM image based on DCNN}, 
  year={2020},
  volume={},
  number={},
  pages={1-4},
  keywords={Training;Computational modeling;Lithography;Resists;Machine learning;Feature extraction;Real-time systems;SEM images;contour extraction;machine leaning (ML);deep convolution neural network (DCNN)},
  doi={10.1109/IWAPS51164.2020.9286798}}

---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Annotating Object Instances with Polygon-RNN

- Semi-automatic annotation of object Instances
- We cast this as POLYGON PREDICTION task rathter than pixel labeling
- Human annotator can correct vertices generated by NN
- Closed polygon. RNN predicts vertex in 2D space at each timestep
- CNN is used to crop the image and learns boundaries, RNN follows those boundardies and exploits priors

The Polygon RNN:
    - VGG-16 arch
    See page 3

Results:
    - Cityscapes dataset
    - Bounding box ground truth labels
    - Heavily speeds up annotation time (4.7x)

Citation:
L. Castrejón, K. Kundu, R. Urtasun and S. Fidler, "Annotating Object Instances with a Polygon-RNN," 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), Honolulu, HI, USA, 2017, pp. 4485-4493, doi: 10.1109/CVPR.2017.477. keywords: {Image segmentation;Labeling;Computer architecture;Agriculture;Two dimensional displays;Kernel},

@INPROCEEDINGS{8099960,
  author={Castrejón, Lluís and Kundu, Kaustav and Urtasun, Raquel and Fidler, Sanja},
  booktitle={2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={Annotating Object Instances with a Polygon-RNN}, 
  year={2017},
  volume={},
  number={},
  pages={4485-4493},
  keywords={Image segmentation;Labeling;Computer architecture;Agriculture;Two dimensional displays;Kernel},
  doi={10.1109/CVPR.2017.477}}

---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Automated image segmentation of scanning electron microscopy images of graphene using U-Net Neural Network

- Distingushes between regions where graphene is and is not present
- Utilizes U-Net
- Trained on 90 high-fidelity images:
     "we find that higher quality is more valuable than higher quantity for achieving good performance."
- Classification accuracy of over 90%
- Materials detection (future work mention in my paper)

---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Automated measurement method based on deep learning for cross-sectional SEM images of semiconductor devices

- Automated method of feature length measurement in cross-sectional SEM images of semiconductors
- Trench patterns
- Task casting
    Object detection and determination of coordinates
    Semantic segmentation for obtaining boundaries
 - 240x faster than manual annotation

- DCNN approach (to the best of their knowledge there is no automated feature profile measurement)


---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Deep learning contour-based method for semi-automatic annotation of manufactured objects in electron microscopy images

This paper talks a good amount about existing approaches

- Semi-automated method of annotation of items in electron microscopy images
- MRE less than 10% and r > 90%
- Constrained Dynamic Match Loss (C-DML)
- Segmentation-assisted approach that demploys a contour-based model
- User draw bounding boxes (I will draw polygons)
- Existing deep learning models are typically fully supervised

- Why classical methods fall short: low-contrast edges and artifacts, existing models are trained on everyday
   images and not as suitable for microscopy
- Base used E2EC, SAM also good but required more compute to be fine-tuned. They fine tune E2EC
- They have contributed a special loss function that is specific to account to physical
   priors of electron microscopy

Experiment:
    - https://b2share.eudat.eu/records/19cc2afd23e34b92b36a1dfd0113a89f
    - https://www.nature.com/articles/sdata2018172

Results:
    - 1244 images using COCO pre-trained weights and using their custom C-DML loss
    - In semiconductor industry, a model or algorithm could be considered reliable enough when achieving
       a r > 0.9 and MRE < 0.1
    - First examine the SOTA contour based models: E2EC and Deep Snake
    - Their approach did well on wire and pillar objects