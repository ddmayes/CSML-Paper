An effective method of contour extraction for SEM image based on DCNN

- Machine learning based method for contour extraction of SEM images
- Custom built DCNN
- Emphasis on CD measurements
- Existing Canny Algorithm for contour extraction mentioned. It fails on poor condition images
- Problem: low contrast SEM images are hard to extract from, existing methods only utilize local info when global 
            info could be leveraged, no distiguishing between top and bottom resist contours, unquality datasets
The deep convolutional neural network:
    - Acts as non-linear mapping from SEM image to contour
    See page 2 

Experiment:
    - Used image denoising and contour refinement
    - 6:2:2 (training:verification:testing) ratio

Results:
    - Evaluated by Fab-centric criteria:
        i  do  not  miss  contour  in  a  visually distinct boundary
        ii do not produce fake contour in background  or  foreground
        iii  flexibility  and  capability  of  repairing broken contours if the broken segments gap is small; 
        iv the contour extraction algorithm should be fast enough to support Fab production needs
    - The DCNN subpressed redundant edges and repaired broken contours within a local area
    - large receptive field and low demand on computation

Citation:
T. Zhou et al., "An effective method of contour extraction for SEM image based on DCNN," 2020 International Workshop on Advanced Patterning Solutions (IWAPS), Chengdu, China, 2020, pp. 1-4, doi: 10.1109/IWAPS51164.2020.9286798. keywords: {Training;Computational modeling;Lithography;Resists;Machine learning;Feature extraction;Real-time systems;SEM images;contour extraction;machine leaning (ML);deep convolution neural network (DCNN)},

@INPROCEEDINGS{9286798,
  author={Zhou, Tao and Shi, Xuelong and YanYan and Li, Chen and Chen, Shoumian and Zhao, Yuhang and Zhou, Wenzhan and Zhou, Kan and Zeng, Xuan},
  booktitle={2020 International Workshop on Advanced Patterning Solutions (IWAPS)}, 
  title={An effective method of contour extraction for SEM image based on DCNN}, 
  year={2020},
  volume={},
  number={},
  pages={1-4},
  keywords={Training;Computational modeling;Lithography;Resists;Machine learning;Feature extraction;Real-time systems;SEM images;contour extraction;machine leaning (ML);deep convolution neural network (DCNN)},
  doi={10.1109/IWAPS51164.2020.9286798}}

---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Annotating Object Instances with Polygon-RNN

- Semi-automatic annotation of object Instances
- We cast this as POLYGON PREDICTION task rathter than pixel labeling
- Human annotator can correct vertices generated by NN
- Closed polygon. RNN predicts vertex in 2D space at each timestep
- CNN is used to crop the image and learns boundaries, RNN follows those boundardies and exploits priors

The Polygon RNN:
    - VGG-16 arch
    See page 3

Results:
    - Cityscapes dataset
    - Bounding box ground truth labels
    - Heavily speeds up annotation time (4.7x)

Citation:
L. Castrejón, K. Kundu, R. Urtasun and S. Fidler, "Annotating Object Instances with a Polygon-RNN," 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), Honolulu, HI, USA, 2017, pp. 4485-4493, doi: 10.1109/CVPR.2017.477. keywords: {Image segmentation;Labeling;Computer architecture;Agriculture;Two dimensional displays;Kernel},

@INPROCEEDINGS{8099960,
  author={Castrejón, Lluís and Kundu, Kaustav and Urtasun, Raquel and Fidler, Sanja},
  booktitle={2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={Annotating Object Instances with a Polygon-RNN}, 
  year={2017},
  volume={},
  number={},
  pages={4485-4493},
  keywords={Image segmentation;Labeling;Computer architecture;Agriculture;Two dimensional displays;Kernel},
  doi={10.1109/CVPR.2017.477}}

---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Automated image segmentation of scanning electron microscopy images of graphene using U-Net Neural Network

- Distingushes between regions where graphene is and is not present
- Utilizes U-Net
- Trained on 90 high-fidelity images:
     "we find that higher quality is more valuable than higher quantity for achieving good performance."
- Classification accuracy of over 90%
- Materials detection (future work mention in my paper)

---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Automated measurement method based on deep learning for cross-sectional SEM images of semiconductor devices

- Automated method of feature length measurement in cross-sectional SEM images of semiconductors
- Trench patterns
- Task casting
    Object detection and determination of coordinates
    Semantic segmentation for obtaining boundaries
 - 240x faster than manual annotation